Returns <- ROC(adjClosed, n = 90, type = "discrete")
tail(dailyReturn)
?tail
dailyReturns <- na.omit(Return.calculate(adjClosed))
SPYReturns <- na.omit(Return.calculate(Ad(SPY)))
tail(dailyReturns)
Returns <- ROC(adjClosed, n = 90, type = "discrete")
Returns <- Returns[complete.cases(Returns),]
for (i in 1: length(index(Returns))){
ranking[[i]] <- rank(as.data.frame(-Returns[i,1:length(Returns[1,])]),
ties.method = "max")}
tail(ranking)
dailyReturns <- na.omit(Return.calculate(adjClosed))
SPYReturns <- na.omit(Return.calculate(Ad(SPY)))
######## Determine portfolio weighting by ranking securities ########
Returns <- ROC(adjClosed, n = 90, type = "discrete")
Returns <- Returns[complete.cases(Returns),]
for (i in 1: length(index(Returns))){
ranking[[i]] <- rank(as.data.frame(-Returns[i,1:length(Returns[1,])]),
ties.method = "max")}
ranking <- as.xts(do.call(rbind, ranking), order.by = index(Returns))
tail(ranking)
weighting <- weighting[endpoints(weighting, on="months"),]
weighting <- xts(((t(apply(ranking, 1, function(data) {return(data <=1)}))) * 1),
order.by = index(ranking))
weighting <- weighting[endpoints(weighting, on="months"),]
tail(weighting)
######## Calculates Strategy Returns ########
strategyReturns <- Return.portfolio(R = dailyReturns, weights = weighting)
tail(strategyReturns)
sum(tail(strategyReturns))
sum(strategyReturns)
######## Evaluates Performance ########
strategyReturns <- merge(strategyReturns, SPYReturns, join='inner')
charts.PerformanceSummary(strategyReturns)
tail(dailyReturns)
tail(getSymbols)
getSymbols
strategyReturns <- Return.portfolio(R = dailyReturns, weights = weighting)
######## Evaluates Performance ########
strategyReturns <- merge(strategyReturns, SPYReturns, join='inner')
charts.PerformanceSummary(strategyReturns)
rbind(table.AnnualizedReturns(strategyReturns),
SortinoRatio(strategyReturns),
maxDrawdown(strategyReturns),
CalmarRatio(strategyReturns))
apply.yearly(strategyReturns, Return.cumulative)
require(PerformanceAnalytics)
require(quantmod)
adjClosed <- ranking <- weighting <- list()
######## Download Stock Price ########
sectorSymbols <- c("MDY", "FEZ", "EEM", "ILF", "EPP", "EDV", "SHY")
getSymbols(sectorSymbols ,from="1990-01-01")
getSymbols("SPY")
for (i in 1 : length(sectorSymbols)) {
adjClosed[[i]] <- Ad(get(sectorSymbols[[i]]))
}
adjClosed <- do.call(cbind, adjClosed)
######## Calculate Daily Returns ########
dailyReturns <- na.omit(Return.calculate(adjClosed))
SPYReturns <- na.omit(Return.calculate(Ad(SPY)))
######## Determine portfolio weighting by ranking securities ########
Returns <- ROC(adjClosed, n = 90, type = "discrete")
Returns <- Returns[complete.cases(Returns),]
for (i in 1: length(index(Returns))){
ranking[[i]] <- rank(as.data.frame(-Returns[i,1:length(Returns[1,])]),
ties.method = "max")}
ranking <- as.xts(do.call(rbind, ranking), order.by = index(Returns))
weighting <- xts(((t(apply(ranking, 1, function(data) {return(data <=1)}))) * 1),
order.by = index(ranking))
weighting <- weighting[endpoints(weighting, on="months"),]
######## Calculates Strategy Returns ########
strategyReturns <- Return.portfolio(R = dailyReturns, weights = weighting)
strategyReturns <- merge(strategyReturns, SPYReturns, join='inner')
charts.PerformanceSummary(strategyReturns)
rbind(table.AnnualizedReturns(strategyReturns),
SortinoRatio(strategyReturns),
maxDrawdown(strategyReturns),
CalmarRatio(strategyReturns))
apply.yearly(strategyReturns, Return.cumulative)
require(PerformanceAnalytics)
require(quantmod)
adjClosed <- ranking <- weighting <- list()
######## Download Stock Price ########
sectorSymbols <- c("MDY", "FEZ", "EEM", "ILF", "EPP", "EDV", "SHY")
getSymbols(sectorSymbols ,from="1990-01-01")
getSymbols("SPY")
adjclosed
dailyReturns
tail(dailyReturns)
tail(getsymbols)
rm(list=())
rm(list=ls())
require(PerformanceAnalytics)
require(quantmod)
adjClosed <- ranking <- weighting <- list()
######## Download Stock Price ########
sectorSymbols <- c("MDY", "FEZ", "EEM", "ILF", "EPP", "EDV", "SHY")
getSymbols(sectorSymbols ,from="1990-01-01")
getSymbols("SPY")
tail(EDV)
tial(SPY)
tail(SPY)
require(PerformanceAnalytics)
require(quantmod)
adjClosed <- ranking <- weighting <- list()
######## Download Stock Price ########
sectorSymbols <- c("MDY", "FEZ", "EEM", "ILF", "EPP", "EDV", "SHY")
getSymbols(sectorSymbols ,from="1990-01-01")
tail(EDV)
rm(list = ls())
write.table(averages_data, "averages_data.txt",row.name = FALSE)
library((plyr))
library(plyr)
# Step 1
# Merge the Traning and test sets to create one data set
x_train  = read.table("train/X_train.txt")
library(plyr)
x_train  = read.table("train/X_train.txt")
y_train  = read.table("train/y_train.txt")
subject_train = read.table("train/subject_train.txt")
library(plyr)
x_train  = read.table("train/X_train.txt")
rm(list=ls())
x_train  = read.table("train/X_train.txt")
y_train  = read.table("train/y_train.txt")
x_train = read.table("X_train")
ls
getwd
getwd()
getwd()
setwd("C:/Users/YuBo/Dropbox/Data_Science/Getting_and_Reading_data")
rm(list=ls())
library(plyr)
x_train  = read.table("train/X_train.txt")
x_train = read.table("X_train.txt")
x_train.train
x_train = read.table("train/X_train.txt")
rm(list=ls())
x_train  = read.table("X_train.txt")
y_train  = read.table("y_train.txt")
subject_train = read.table("subject_train.txt")
x_test = read.table("X_test.txt")
y_test = read.table("y_test.txt")
subject_test = read.table("subject_test.txt")
x_data = rbind(x_train,x_test)
y_dta = rbind(y_train,y_test)
#creat 'subject' data set
subject_data = rbind(subject_train,subject_test)
feature = read.table("features.txt")
mean_and_std_features = grep("-(mean\std)\\(\\)",features[, 2]))
mean_and_std_features = grep("-(mean|std)\\(\\)",features[, 2]))
mean_and_std_features = grep("-(mean|std)\\(\\)",features[, 2])
features = read.table("features.txt")
View(feature)
features = read.table("features.txt")
mean_and_std_features = grep("-(mean|std)\\(\\)",features[, 2])
x_data = x_data[, mean_and_std_features]
names(x_data) = features[mean_and_std_features,2]
activities = read.table("activity_labels.txt")
y_data[, 1] = activities[y_data[,1],2]
View(activities)
activities = read.table("activity_labels.txt")
y_data[, 1] = activities[y_data[,1],2]
y_data[, 1] = activities[y_data[, 1],2]
y_data[, 1]
y_data = rbind(y_train,y_test)
y_data[, 1] = activities[y_data[, 1],2]
names(y_data) = "activity"
names(subject_data) = "subject"
all_data = cbind(x_data,y_data,subject_data)
averages_data = ddply(all_data,.(subject,activity), function(x) colMeans(x[, 1:66]))
write.table(averages_data, "averages_data.txt",row.name = FALSE)
rm(list=ls())
library(plyr)
rm(list=ls())
library(plyr)
# Step 1
# Merge the Traning and test sets to create one data set
x_train  = read.table("X_train.txt")
y_train  = read.table("y_train.txt")
subject_train = read.table("subject_train.txt")
x_test = read.table("X_test.txt")
y_test = read.table("y_test.txt")
subject_test = read.table("subject_test.txt")
# create 'X' data set
x_data = rbind(x_train,x_test)
# creat 'y' data set
y_data = rbind(y_train,y_test)
#creat 'subject' data set
subject_data = rbind(subject_train,subject_test)
# Step 2
# Extract onlyy the measurements on the mean and stdr deviation for each measurement
features = read.table("features.txt")
# get only columns with mean() or stad() in their names
mean_and_std_features = grep("-(mean|std)\\(\\)",features[, 2])
# subset the desired columns
x_data = x_data[, mean_and_std_features]
# correct the columns names
names(x_data) = features[mean_and_std_features,2]
# Step 3
# Use descriptive activity names to name the activities in the data set
activities = read.table("activity_labels.txt")
# update values with correct activity names
y_data[, 1] = activities[y_data[, 1],2]
# correct column name
names(y_data) = "activity"
# Step 4
# Appropiately label the data set with descriptive variable names
names(subject_data) = "subject"
# bind all the data in signle dtaa set
all_data = cbind(x_data,y_data,subject_data)
# Step 5
# cearte a second, independet tidy data set with the average of each variable
# for each acticiry and each subject
# 66 <- 68 colums but last two (acticiry & subject)
averages_data = ddply(all_data,.(subject,activity), function(x) colMeans(x[, 1:66]))
write.table(averages_data, "averages_data.txt",row.name = FALSE)
rm(list=ls())
datalocation = "./household_power_consumption.txt"
data = read.table(datalocation,header = TRUE, sep = ";",stringsAsFactors = FALSE, dec = ".")
getwd()
setwd("C:/Users/YuBo/Dropbox/Data_Science/Exploratory_Data_Analysis")
datalocation = "./household_power_consumption.txt"
data = read.table(datalocation,header = TRUE, sep = ";",stringsAsFactors = FALSE, dec = ".")
subsetdata = data[data$Date %in% c("1/2/2007","2/2/2007") ,]
datatime = strptime(paste(subsetdata$Date, subsetdata$Time, sep = " "),"%d/%m/%Y %H:%M:%S")
gap = as.numeric(subsetdata$Global_active_power)
png("plot2.png",width=480,height=480)
plot(datatime,gap,type = "l",xlab="",ylab = "Global Active Power (kw)")
dev.off()
rm(list=ls())
setwd("C:/Users/YuBo/Dropbox/Data_Science/Exploratory_Data_Analysis")
rm(list=ls())
setwd("C:/Users/YuBo/Dropbox/Data_Science/Exploratory_Data_Analysis")
datalocation = "./household_power_consumption.txt"
data = read.table(datalocation,header = TRUE, sep = ";",stringsAsFactors = FALSE, dec = ".")
subsetdata = data[data$Date %in% c("1/2/2007","2/2/2007") ,]
datatime = strptime(paste(subsetdata$Date, subsetdata$Time,sep = " "),"%d/%m/%Y %H:%M:%S")
gap = as.numeric(subsetdata$Global_active_power)
submetering1 = as.numeric(subsetdata$Sub_metering_1)
submetering2 = as.numeric(subsetdata$Sub_metering_2)
submetering3 = as.numeric(subsetdata$Sub_metering_3)
png("plot3.png",width = 480,height = 480)
plot(datatime,submeterting1,type = "1", ylab = "Energy Submetering", xlab = "")
plot(datatime,submetering1,type = "1", ylab = "Energy Submetering", xlab = "")
plot(datatime,submetering1,type = "l", ylab = "Energy Submetering", xlab = "")
lines(datatime,submetering2,type = "l",col = "red")
lines(datatime,submetering3,type = "l", col = "blue")
legend("topright",c("Sub_metering1","Sub_meterting2","Sub_metering3"),lty = 1, lwd = 2.5, col=c("black","red","blue"))
dev.off()
subsetdata = data[data$Date %in% c("1/2/2007","2/2/2007") ,]
datatime = strptime(paste(subsetdata$Date, subsetdata$Time,sep = " "),"%d/%m/%Y %H:%M:%S")
gap = as.numeric(subsetdata$Global_active_power)
voltage = as.numeric(subsetdata$Voltage)
submetering1 = as.numeric(subsetdata$Sub_metering_1)
submetering2 = as.numeric(subsetdata$Sub_metering_2)
submetering3 = as.numeric(subsetdata$Sub_metering_3)
png("plot4.png",width = 480, height = 480)
par(mfrow = c(2,2))
plot(datatime, gap, type = "l", xlab = "", ylab = "Global Acitve Power",cex = 0.2)
plot(datatime,voltage, typt = "l",xlab = "datatime",ylab = "Voltage")
plot(datatime,submetering1,type = "l",ylab = "Energy Submetering", xlab = "")
plot(datatime, gap, type = "l", xlab = "", ylab = "Global Acitve Power",cex = 0.2)
plot(datatime,voltage, typt = "l",xlab = "datatime",ylab = "Voltage")
plot(datatime,voltage, type = "l",xlab = "datatime",ylab = "Voltage")
plot(datatime,submetering1,type = "l",ylab = "Energy Submetering", xlab = "")
lines(datatime, submetering2,type = "l",col = "red")
lines(datatime, submetering3,type = "l",col = "blue")
legend("topright",c("Sub_metering1","Sub_meterting2","Sub_metering3"),lty = 1, lwd = 2.5, col=c("black","red","blue"),bty = "o")
plot(datatime,gap,type = "l", xlab = "datatime", ylab = "Global Active Power")
dev.off()
getwd()
setwd("C:/Users/YuBo/Dropbox/Data_Science/Getting_and_Reading_data")
rm(list=ls())
library(plyr)
# Step 1
# Merge the Traning and test sets to create one data set
x_train  = read.table("X_train.txt")
y_train  = read.table("y_train.txt")
subject_train = read.table("subject_train.txt")
x_test = read.table("X_test.txt")
y_test = read.table("y_test.txt")
subject_test = read.table("subject_test.txt")
# create 'X' data set
x_data = rbind(x_train,x_test)
# creat 'y' data set
y_data = rbind(y_train,y_test)
#creat 'subject' data set
subject_data = rbind(subject_train,subject_test)
# Step 2
# Extract onlyy the measurements on the mean and stdr deviation for each measurement
features = read.table("features.txt")
# get only columns with mean() or stad() in their names
mean_and_std_features = grep("-(mean|std)\\(\\)",features[, 2])
# subset the desired columns
x_data = x_data[, mean_and_std_features]
# correct the columns names
names(x_data) = features[mean_and_std_features,2]
# Step 3
# Use descriptive activity names to name the activities in the data set
activities = read.table("activity_labels.txt")
# update values with correct activity names
y_data[, 1] = activities[y_data[, 1],2]
# correct column name
names(y_data) = "activity"
# Step 4
# Appropiately label the data set with descriptive variable names
names(subject_data) = "subject"
# bind all the data in signle dtaa set
all_data = cbind(x_data,y_data,subject_data)
# Step 5
# cearte a second, independet tidy data set with the average of each variable
# for each acticiry and each subject
# 66 <- 68 colums but last two (acticiry & subject)
averages_data = ddply(all_data,.(subject,activity), function(x) colMeans(x[, 1:66]))
#write.table(averages_data, "averages_data.txt",row.name = FALSE)
write.table(averages_data, "tidy.txt",row.name = FALSE)
rm(list=ls())
setwd('C:/Users/YuBo/Dropbox/Data_Science/Reproducible_Research/RepData_PeerAssessment1')
data = read.csv("activity.csv")
#########################################################################################
library(ggplot2)
total.steps = tapply(data$steps,data$date, FUN = sum, na.rm = TRUE)
qplot(total.steps, binwidth = 1000, xlab = "total number of steps taken each day")
mean(total.steps, na.rm = TRUE)
median(total.steps, na.rm = TRUE)
#########################################################################################
library(ggplot2)
averages = aggregate(x = list(steps = data$steps), by = list(interval=data$interval), FUN = mean, na.rm = TRUE)
ggplot(data  = averages, aes(x = interval, y = steps)) +
geom_line() +
xlab("5 - minute interval") +
ylab("average number of steps taken")
##########################################################################################
averages[which.max(averages$steps),]
###########   How many missing   #########################################################
missing = is.na(data$steps)
table(missing)
##########################################################################################
# Replace all missing value with the mean value of its 5-min interval
# Replace all missing value with the mean value of its 5-min interval
fill.value = function(steps, interval){
filled = NA
if (!is.na(steps))
filled = c(step)
else
filled = (averages[averages$interval == interval, "steps"])
}
filled.data = data
filled.data$steps = mapply(fill.value, filled.data$steps, filled.data$interval)
##########################################################################################
total.steps = tapply(filled.data$steps, filled.data$data, FUN = sum)
qplot(total.steps, binwidth = 1000, xlab = "Total number of steps taken each day")
mean(total.steps)
filled.data$steps = mapply(fill.value, filled.data$steps, filled.data$interval)
fill.value = function(steps, interval){
filled = NA
if (!is.na(steps))
filled = c(step)
else
filled = (averages[averages$interval == interval, "steps"])
}
filled.data = data
filled.data$steps = mapply(fill.value, filled.data$steps, filled.data$interval)
total.steps = tapply(filled.data$steps, filled.data$data, FUN = sum)
total.steps = tapply(filled.data$steps, filled.data$date, FUN = sum)
fill.value = function(steps, interval){
filled = NA
if (!is.na(steps))
filled = c(step)
else
filled = (averages[averages$interval == interval, "steps"])
}
filled.data = data
filled.data$steps = mapply(fill.value, filled.data$steps, filled.data$interval)
##########################################################################################
total.steps = tapply(filled.data$steps, filled.data$date, FUN = sum)
rm(list=ls())
setwd('C:/Users/YuBo/Dropbox/Data_Science/Reproducible_Research/RepData_PeerAssessment1')
data = read.csv("activity.csv")
#########################################################################################
library(ggplot2)
total.steps = tapply(data$steps,data$date, FUN = sum, na.rm = TRUE)
qplot(total.steps, binwidth = 1000, xlab = "total number of steps taken each day")
mean(total.steps, na.rm = TRUE)
median(total.steps, na.rm = TRUE)
#########################################################################################
library(ggplot2)
averages = aggregate(x = list(steps = data$steps), by = list(interval=data$interval), FUN = mean, na.rm = TRUE)
ggplot(data  = averages, aes(x = interval, y = steps)) +
geom_line() +
xlab("5 - minute interval") +
ylab("average number of steps taken")
##########################################################################################
averages[which.max(averages$steps),]
###########   How many missing   #########################################################
missing = is.na(data$steps)
table(missing)
##########################################################################################
# Replace all missing value with the mean value of its 5-min interval
fill.value = function(steps, interval){
filled = NA
if (!is.na(steps))
filled = c(step)
else
filled = (averages[averages$interval == interval, "steps"])
}
filled.data = data
filled.data$steps = mapply(fill.value, filled.data$steps, filled.data$interval)
total.steps = tapply(filled.data$steps, filled.data$date, FUN = sum)
rm(list=ls())
setwd('C:/Users/YuBo/Dropbox/Data_Science/Reproducible_Research/RepData_PeerAssessment1')
data = read.csv("activity.csv")
#########################################################################################
library(ggplot2)
total.steps = tapply(data$steps,data$date, FUN = sum, na.rm = TRUE)
qplot(total.steps, binwidth = 1000, xlab = "total number of steps taken each day")
mean(total.steps, na.rm = TRUE)
median(total.steps, na.rm = TRUE)
#########################################################################################
library(ggplot2)
averages = aggregate(x = list(steps = data$steps), by = list(interval=data$interval), FUN = mean, na.rm = TRUE)
ggplot(data  = averages, aes(x = interval, y = steps)) +
geom_line() +
xlab("5 - minute interval") +
ylab("average number of steps taken")
##########################################################################################
averages[which.max(averages$steps),]
###########   How many missing   #########################################################
missing = is.na(data$steps)
table(missing)
##########################################################################################
# Replace all missing value with the mean value of its 5-min interval
fill.value = function(steps, interval){
filled = NA
if (!is.na(steps))
filled = c(steps)
else
filled = (averages[averages$interval == interval, "steps"])
}
filled.data = data
filled.data$steps = mapply(fill.value, filled.data$steps, filled.data$interval)
total.steps = tapply(filled.data$steps, filled.data$date, FUN = sum)
qplot(total.steps, binwidth = 1000, xlab = "Total number of steps taken each day")
mean(total.steps)
median(total.steps)
#########################################################################################
weekday.or.weekend = function(date){
day = weekdays(date)
if (day %in% c("Monday","Tuesday","Wednesday","Thursday","Friday"))
return("weekday")
else if (date %in% c("Saturday", "Sunday"))
return("weekend")
else
stop("invalid date")
}
filled.data$date = as.Date(filled.data$date)
filled.data$day = sapply(filled.data$date, FUN = weekday.or.weekend)
rm(list=ls())
setwd('C:/Users/YuBo/Dropbox/Data_Science/Reproducible_Research/RepData_PeerAssessment1')
data = read.csv("activity.csv")
#########################################################################################
library(ggplot2)
total.steps = tapply(data$steps,data$date, FUN = sum, na.rm = TRUE)
qplot(total.steps, binwidth = 1000, xlab = "total number of steps taken each day")
mean(total.steps, na.rm = TRUE)
median(total.steps, na.rm = TRUE)
#########################################################################################
library(ggplot2)
averages = aggregate(x = list(steps = data$steps), by = list(interval=data$interval), FUN = mean, na.rm = TRUE)
ggplot(data  = averages, aes(x = interval, y = steps)) +
geom_line() +
xlab("5 - minute interval") +
ylab("average number of steps taken")
##########################################################################################
averages[which.max(averages$steps),]
###########   How many missing   #########################################################
missing = is.na(data$steps)
table(missing)
##########################################################################################
# Replace all missing value with the mean value of its 5-min interval
fill.value = function(steps, interval){
filled = NA
if (!is.na(steps))
filled = c(steps)
else
filled = (averages[averages$interval == interval, "steps"])
}
filled.data = data
filled.data$steps = mapply(fill.value, filled.data$steps, filled.data$interval)
##########################################################################################
total.steps = tapply(filled.data$steps, filled.data$date, FUN = sum)
qplot(total.steps, binwidth = 1000, xlab = "Total number of steps taken each day")
mean(total.steps)
median(total.steps)
#########################################################################################
weekday.or.weekend = function(date){
day = weekdays(date)
if (day %in% c("Monday","Tuesday","Wednesday","Thursday","Friday"))
return("weekday")
else if (day %in% c("Saturday", "Sunday"))
return("weekend")
else
stop("invalid date")
}
filled.data$date = as.Date(filled.data$date)
filled.data$day = sapply(filled.data$date, FUN = weekday.or.weekend)
averages = aggregate(steps ~ interval + day, data = filled.data, mean)
ggplot(averages, aes(interval, steps)) + geom_line() + facet_grid(day ~ .) +
xlab("5 - minute interval") + ylab("Number of steps")
install.packages("knitr")
